{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compares quartet inference on simulated data by a softmax regression machine learning model to that by SVDquartets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import re\n",
    "import random\n",
    "from itertools import compress\n",
    "import itertools\n",
    "import math\n",
    "from operator import itemgetter\n",
    "import sys\n",
    "from Bio import Phylo\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function\n",
    "Reads in sequence data generated on a phylogeny, along with the phylogeny. \n",
    "\n",
    "Returns a sequence matrix split on t1, t2 | t3, t4, as well as a three-element array of what the real split is in the tree. \n",
    "\n",
    "To define the real split on the tree:\n",
    "\n",
    "[1, 0, 0] = t1, t2 | t3, t4\n",
    "\n",
    "[0, 1, 0] = t1, t3 | t2, t4\n",
    "\n",
    "[0, 0, 1] = t1, t4 | t2, t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_quint_pred_actual(sequencedata, phylogeny,tipnames):\n",
    "    # read in data\n",
    "\n",
    "    fname = sequencedata\n",
    "    with open(fname) as f:\n",
    "        sequences = f.readlines()\n",
    "\n",
    "    # remove whitespace characters like `\\n` at the end of each line\n",
    "\n",
    "    sequences = [x.strip() for x in sequences] \n",
    "    sequences.pop(0)\n",
    "\n",
    "    # get sequences  and identify quintet taxa\n",
    "    names = [sequences[i][0:10].strip(\" \") for i in range(len(sequences))]\n",
    "    iso_sequences = [sequences[i][10:].strip(\" \") for i in range(len(sequences))]\n",
    "    \n",
    "    # so we're only testing one possible quartet per tree... Easy to expand this to test every quintet per tree\n",
    "    interestednames = tipnames # this should be a list of four tip names... e.g. [\"t1\",\"t2\",\"t3\",\"t4]\n",
    "    taxa_ids = list(itertools.chain.from_iterable([list(compress(range(10),i)) for i in [[q == i for i in names] for q in interestednames]]))\n",
    "    \n",
    "    #taxa_ids = [3,2,8,9]\n",
    "    #fourtaxa = [names[i] for i in taxa_ids]\n",
    "\n",
    "    tempobj = [iso_sequences[i] for i in taxa_ids]\n",
    "\n",
    "    # eliminate non-snps\n",
    "\n",
    "    ind_samples = []\n",
    "    for i in range(len(tempobj[0])):\n",
    "        currentbase = ([tempobj[q][i] for q in range(len(tempobj))])\n",
    "        if (len(set(currentbase)) > 1):\n",
    "            ind_samples.append(currentbase)\n",
    "    ind_samples_reset = ind_samples\n",
    "\n",
    "    # separate sequences by fifth taxon\n",
    "\n",
    "    ind_samples = np.array(ind_samples_reset)\n",
    "    ind_samples = np.where(ind_samples=='A',0,ind_samples)\n",
    "    ind_samples = np.where(ind_samples=='C',1,ind_samples)\n",
    "    ind_samples = np.where(ind_samples=='G',2,ind_samples)\n",
    "    ind_samples = np.where(ind_samples=='T',3,ind_samples)\n",
    "    ind_samples = ind_samples.astype(int)\n",
    "\n",
    "    # get the matrices\n",
    "    indexmat = np.array(range(16))\n",
    "    indexmat.shape=(4,4)\n",
    "    # order across matrix is 00,01,02,03,10,11,12,13,20,21,22,23,30,31,32,33\n",
    "    fullmat0123 = np.zeros(shape=(16,16))\n",
    "    arr0123 = ind_samples\n",
    "    for i in range(len(arr0123)):\n",
    "                # get row number \n",
    "        rownum = int(indexmat[arr0123[i][0],arr0123[i][1]])\n",
    "                # get col number\n",
    "        colnum = int(indexmat[arr0123[i][2],arr0123[i][3]])\n",
    "        fullmat0123[rownum,colnum] = fullmat0123[rownum,colnum] + 1\n",
    "    #allmats.append(fullmat0123)\n",
    "\n",
    "    # predict the true quintet\n",
    "\n",
    "    # compare with actual quintet\n",
    "\n",
    "    tree = Phylo.read(phylogeny, 'newick')\n",
    "\n",
    "    tipnames = [names[i] for i in taxa_ids]\n",
    "    indexing = np.array([[0,1],[0,2],[0,3],[1,2],[1,3],[2,3]])\n",
    "\n",
    "    alldists = [tree.distance(tipnames[0],tipnames[1]),\n",
    "                tree.distance(tipnames[0],tipnames[2]),\n",
    "                tree.distance(tipnames[0],tipnames[3]),\n",
    "                tree.distance(tipnames[1],tipnames[2]),\n",
    "                tree.distance(tipnames[1],tipnames[3]),\n",
    "                tree.distance(tipnames[2],tipnames[3])]\n",
    "\n",
    "    min_tree_pairs1, min_pair_val1 = min(enumerate(alldists), key=itemgetter(1))\n",
    "    \n",
    "    paired_taxa =  [tipnames[i] for i in list(indexing[min_tree_pairs1])] + [tipnames[i] for i in list(set([0,1,2,3]) ^ set(list(indexing[min_tree_pairs1])))]\n",
    "    quartet_numbers = list(itertools.chain.from_iterable([list(compress(range(10),i)) for i in [[q == i for i in names] for q in paired_taxa]]))\n",
    "    \n",
    "    # is this a 0123, 0213, or 0312?\n",
    "    correct_config = np.array([(set([taxa_ids[i] for i in [0,1,2,3]][2:4]) == set(quartet_numbers[2:4]) or \n",
    "                                    set([taxa_ids[i] for i in [0,1,2,3]][2:4]) == set(quartet_numbers[0:2])),\n",
    "                                (set([taxa_ids[i] for i in [0,2,1,3]][2:4]) == set(quartet_numbers[2:4]) or \n",
    "                                    set([taxa_ids[i] for i in [0,2,1,3]][2:4]) == set(quartet_numbers[0:2])),\n",
    "                                (set([taxa_ids[i] for i in [0,3,1,2]][2:4]) == set(quartet_numbers[2:4]) or \n",
    "                                    set([taxa_ids[i] for i in [0,3,1,2]][2:4]) == set(quartet_numbers[0:2]))]).astype(int)\n",
    "    \n",
    "    return(taxa_ids,quartet_numbers,paired_taxa,correct_config,fullmat0123)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the function to all of our tree/sequence combinations, saving the sequence matrices as `images` and the true splits as `labels`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i in range(2001)[1:2001]:\n",
    "    test = compare_quint_pred_actual(sequencedata=\"tree_seqs/test\" + str(i) + \".dat\",phylogeny=\"random_trees/samp\" + str(i) + \".phy\",tipnames=[\"t1\",\"t2\",\"t3\",\"t4\"])\n",
    "    images.append(test[4].flatten()/max(test[4].flatten()))\n",
    "    labels.append(test[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run a very simple (as in, from the tensorflow tutorial) softmax regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985986\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 256])\n",
    "W = tf.Variable(tf.zeros([256, 3]))\n",
    "b = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.6).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for _ in range(1000):\n",
    "  batch = np.random.choice(1000, 50)\n",
    "  batch_xs, batch_ys = np.array([images[i] for i in batch]),np.array([labels[i] for i in batch])\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: images[1001:2000], y_: labels[1001:2000]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = sess.run(y, feed_dict={x: [images[7]]})\n",
    "int(tf.argmax(predictions,1).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows 98.6% successful prediction of quartet arrangements by our simple machine learning model.\n",
    "\n",
    "This high rate is easy to accomplish because the seq-gen settings are really basic, and we have lots of loci to work with. With real data, we'd want more sophisticated models and would still probably end up with lower rates of success. Model training relies on simulated sequence data, so making the jump to empirical data might be hard. We'd need a way to test robustness of the model to variation in data. \n",
    "\n",
    "Many of the branch lengths on the simulated trees used here ended up being very short, so the high rate of success is still a good sign. \n",
    "\n",
    "This is also promising because it could be easily extended beyond four taxa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVDquartets inference on same data\n",
    "\n",
    "The loop below makes a bunch of quartet decisions on the same set of sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosenindexlist = []\n",
    "for w in range(1001,2001):\n",
    "    sequencedata = \"tree_seqs/test\" + str(w) + \".dat\"\n",
    "    # read in data\n",
    "\n",
    "    fname = sequencedata\n",
    "    with open(fname) as f:\n",
    "        sequences = f.readlines()\n",
    "\n",
    "    # remove whitespace characters like `\\n` at the end of each line\n",
    "\n",
    "    sequences = [x.strip() for x in sequences] \n",
    "    sequences.pop(0)\n",
    "\n",
    "    # get sequences  and identify quintet taxa\n",
    "    names = [sequences[i][0:10].strip(\" \") for i in range(len(sequences))]\n",
    "    iso_sequences = [sequences[i][10:].strip(\" \") for i in range(len(sequences))]\n",
    "    \n",
    "    # so we're only testing one possible quartet per tree... Easy to expand this to test every quintet per tree\n",
    "    interestednames = [\"t1\",\"t2\",\"t3\",\"t4\"]\n",
    "    taxa_ids = list(itertools.chain.from_iterable([list(compress(range(10),i)) for i in [[q == i for i in names] for q in interestednames]]))\n",
    "    \n",
    "    #taxa_ids = [3,2,8,9]\n",
    "    #fourtaxa = [names[i] for i in taxa_ids]\n",
    "\n",
    "    tempobj = [iso_sequences[i] for i in taxa_ids]\n",
    "\n",
    "    # eliminate non-snps\n",
    "\n",
    "    ind_samples = []\n",
    "    for i in range(len(tempobj[0])):\n",
    "        currentbase = ([tempobj[q][i] for q in range(len(tempobj))])\n",
    "        if (len(set(currentbase)) > 1):\n",
    "            ind_samples.append(currentbase)\n",
    "    ind_samples_reset = ind_samples\n",
    "\n",
    "    # separate sequences by fifth taxon\n",
    "\n",
    "    ind_samples = np.array(ind_samples_reset)\n",
    "    ind_samples = np.where(ind_samples=='A',0,ind_samples)\n",
    "    ind_samples = np.where(ind_samples=='C',1,ind_samples)\n",
    "    ind_samples = np.where(ind_samples=='G',2,ind_samples)\n",
    "    ind_samples = np.where(ind_samples=='T',3,ind_samples)\n",
    "    ind_samples = ind_samples.astype(int)\n",
    "    \n",
    "    possible_configs = [[0,1,2,3],[0,2,1,3],[0,3,1,2]]\n",
    "    # get the matrices\n",
    "    indexmat = np.array(range(16))\n",
    "    indexmat.shape=(4,4)\n",
    "    # order across matrix is 00,01,02,03,10,11,12,13,20,21,22,23,30,31,32,33\n",
    "    fullmat0123 = np.zeros(shape=(16,16))\n",
    "    arr0123 = ind_samples\n",
    "    for i in range(len(arr0123)):\n",
    "                # get row number \n",
    "        rownum = int(indexmat[arr0123[i][0],arr0123[i][1]])\n",
    "                # get col number\n",
    "        colnum = int(indexmat[arr0123[i][2],arr0123[i][3]])\n",
    "        fullmat0123[rownum,colnum] = fullmat0123[rownum,colnum] + 1\n",
    " \n",
    "\n",
    "    fullmat0213 = np.zeros(shape=(16,16))\n",
    "    arr0213 = ind_samples[:,possible_configs[1]]\n",
    "    for i in range(len(arr0213)):\n",
    "        # get row number \n",
    "        rownum = int(indexmat[arr0213[i][0:2][0],arr0213[i][0:2][1]])\n",
    "        # get col number\n",
    "        colnum = int(indexmat[arr0213[i][2:4][0],arr0213[i][2:4][1]])\n",
    "        fullmat0213[rownum,colnum] = fullmat0213[rownum,colnum] + 1\n",
    "\n",
    "    fullmat0312 = np.zeros(shape=(16,16))\n",
    "    arr0312 = ind_samples[:,possible_configs[2]]\n",
    "    for i in range(len(arr0312)):\n",
    "        # get row number \n",
    "        rownum = int(indexmat[arr0312[i][0:2][0],arr0312[i][0:2][1]])\n",
    "        # get col number\n",
    "        colnum = int(indexmat[arr0312[i][2:4][0],arr0312[i][2:4][1]])\n",
    "        fullmat0312[rownum,colnum] = fullmat0312[rownum,colnum] + 1\n",
    "    #score the matrices here\n",
    "    scores = [math.sqrt(np.sum(np.square(np.linalg.svd(fullmat0123)[1][10:15]))),math.sqrt(np.sum(np.square(np.linalg.svd(fullmat0213)[1][10:15]))),math.sqrt(np.sum(np.square(np.linalg.svd(fullmat0312)[1][10:15])))]\n",
    "    #choose best scoring matrix\n",
    "    min_index, min_value = min(enumerate(scores), key=itemgetter(1))\n",
    "    chosenindex = np.array([0,0,0])\n",
    "    chosenindex[min_index] = 1\n",
    "    chosenindexlist.append(chosenindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we tally up the correctly inferred quartets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "truequarts = [labels[i] for i in range(1000,2000)]\n",
    "tally = 0\n",
    "for w in range(len(truequarts)):\n",
    "    if (sum(truequarts[w] == chosenindexlist[w]) == 3):\n",
    "        tally = tally + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally, get the percent correct under SVDquartets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tally / 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 93.5 percent of quartets inferred by SVDquartets are correct, although I won't rule out the possibility that I'm doing the scoring incorrectly.\n",
    "\n",
    "The softmax model had the benefit of being tailored specifically to the simulated data and making predictions on data generated under the same model. SVDquartets quartet selection performs pretty well regardless, which we can't yet say for softmax or a similar machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "\n",
    "*  Mix together models of sequence evolution for training set, perform inference on mixed simulations.\n",
    "*  Compare success of different types of trainings on empirical inference (even showing consistency would go a long way).\n",
    "*  Improve machine learning model past single layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import ipyrad as ip\n",
    "import subprocess\n",
    "from ipyrad.assemble.util import IPyradWarningExit, progressbar, Params\n",
    "from toytree import ete3mini as ete3\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltips = [\"t1\",\"t2\",\"t3\",\"t4\",\"t5\",\"t6\",\"t7\",\"t8\",\"t9\",\"t10\"]\n",
    "alltipcombns=list(itertools.combinations(alltips, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=100\n",
    "all_mats = [compare_quint_pred_actual(sequencedata=\"tree_seqs/test\" + str(i) + \".dat\",phylogeny=\"random_trees/samp\" + str(i) + \".phy\",tipnames=q)[4] for q in alltipcombns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosenquarts = []\n",
    "for i in all_mats:\n",
    "    predictions = sess.run(y, feed_dict={x: [i.flatten()/max(i.flatten())]})\n",
    "    chosenquarts.append(int(tf.argmax(predictions,1).eval()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correctquarts = [[alltipcombns[q][i] for i in [[0,1,2,3],[0,2,1,3],[0,3,1,2]][chosenquarts[q]]] for q in range(len(chosenquarts))]\n",
    "names = [\"t1\",\"t2\",\"t3\",\"t4\",\"t5\",\"t6\",\"t7\",\"t8\",\"t9\",\"t10\"]\n",
    "ids = range(len(names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correctquarts= np.array(correctquarts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for q in range(len(names)):\n",
    "    correctquarts = [[re.sub(r'\\b'+ names[q] +r'\\b', str(ids[q]), correctquarts[w][i]) for i in range(4)] for w in range(len(correctquarts))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dump_qmc(quartets,tempfiledir):\n",
    "    \"\"\"\n",
    "    Writes the inferred quartet sets from the database to a text \n",
    "    file to be used as input for QMC. Quartets that had no information\n",
    "    available (i.e., no SNPs) were written to the database as 0,0,0,0\n",
    "    and are excluded here from the output.\n",
    "    \"\"\"\n",
    "\n",
    "    ## open the h5 database\n",
    "    #with h5py.File(self.database.output, 'r') as io5:\n",
    "\n",
    "        ## create an output file for writing\n",
    "    tempfile = os.path.join(tempfiledir,\"quartets.txt\")\n",
    "    with open(tempfile, 'w') as qdump:\n",
    "\n",
    "        ## pull from db\n",
    "        #for idx in xrange(0, self.params.nquartets, self._chunksize):\n",
    "            #quarts = quartets\n",
    "\n",
    "            ## shuffle and format for qmc\n",
    "            #np.random.shuffle(quarts)\n",
    "            chunk = [\"{},{}|{},{}\".format(*i) for i in quartets]\n",
    "            qdump.write(\"\\n\".join(chunk)+\"\\n\")\n",
    "\n",
    "\n",
    "def _run_qmc(tempfiledir, tempfilename,treename,tipnames):\n",
    "    \"\"\"\n",
    "    Runs quartet max-cut QMC on the quartets qdump file.\n",
    "    \"\"\"\n",
    "\n",
    "    ## build command\n",
    "    thetmptree = os.path.join(tempfiledir, \"tmptre.phy\")\n",
    "    cmd = [ip.bins.qmc, \"qrtt=\"+tempfilename, \"otre=\"+thetmptree]\n",
    "\n",
    "    ## run it\n",
    "    proc = subprocess.Popen(cmd, stderr=subprocess.STDOUT, stdout=subprocess.PIPE)\n",
    "    res = proc.communicate()\n",
    "    #if proc.returncode:\n",
    "    #    print(proc.returncode)\n",
    "    #    raise IPyradWarningExit(res[1])\n",
    "\n",
    "    ## parse tmp file written by qmc into a tree and rename it\n",
    "    with open(thetmptree, 'r') as intree:\n",
    "        tre = ete3.Tree(intree.read().strip())\n",
    "        names = tre.get_leaves()\n",
    "        for name in names:\n",
    "            name.name = tipnames[int(name.name)]\n",
    "        tmptre = tre.write(format=9)\n",
    "\n",
    "    ## save the tree to file\n",
    "    #if boot:\n",
    "    #    self.trees.boots = os.path.join(self.dirs, self.name+\".boots\")\n",
    "    #    with open(self.trees.boots, 'a') as outboot:\n",
    "    #        outboot.write(tmptre+\"\\n\")\n",
    "    #else:\n",
    "    treepath  = os.path.join(tempfiledir, treename+\".tree\")\n",
    "    with open(treepath, 'w') as outtree:\n",
    "        outtree.write(tmptre)\n",
    "\n",
    "    ## save the file\n",
    "    #treepath._save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dump_qmc(correctquarts,\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_run_qmc(tempfiledir=\"\",tempfilename = \"quartets.txt\",treename=\"mytree\",tipnames=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mammals dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib2 import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name your current quartet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fourtaxa = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all independent snps for quartet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genesnps = np.array([]).reshape(0,4)\n",
    "for gene in range(1,447):\n",
    "    fname = \"download_simseqs/song-mammalian-bio_completely_processed/424genes/relabeled_data/\"+ str(gene) +\".fasta_relabeled.phy\"\n",
    "    if Path(fname).is_file():\n",
    "        raw = open(fname, 'r')\n",
    "        snps = file.read(raw) \n",
    "        snps = snps.split('\\n')\n",
    "        # remove whitespace characters like `\\n` at the end of each line\n",
    "        snps = [x.strip() for x in snps] \n",
    "        snps.pop(0)\n",
    "        [snps.pop(i) for i in range(len(snps)) if not len(snps[i])]\n",
    "\n",
    "        snps = [snps[i].split(\" \") for i in range(len(snps))]\n",
    "        snps = [filter(None, snps[i]) for i in range(len(snps))]\n",
    "\n",
    "        ids = [snps[i][0] for i in range(len(snps))]\n",
    "        sequences = [snps[i][1] for i in range(len(snps))]\n",
    "        fourfullseqs = [sequences[i] for i in fourtaxa]\n",
    "        snpseqs = np.array([]).reshape(0,4)\n",
    "        for q in range(len(fourfullseqs[0])):\n",
    "            current4bases=[fourfullseqs[i][q] for i in range(4)]\n",
    "            if ((len(set(current4bases).union(set(['A','G','C','T']))) == 4) and (len(set(current4bases)) > 1)):\n",
    "                snpseqs = np.vstack([snpseqs, current4bases])\n",
    "        if len(snpseqs):\n",
    "            genesnps = np.vstack([genesnps,snpseqs[np.random.choice(len(snpseqs))]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the quartet matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snps = np.array(genesnps)\n",
    "possible_configs = [0,1,2,3]\n",
    "snps = np.where(snps=='A',0,snps)\n",
    "snps = np.where(snps=='C',1,snps)\n",
    "snps = np.where(snps=='G',2,snps)\n",
    "snps = np.where(snps=='T',3,snps)\n",
    "snps = snps.astype(int)\n",
    "finalsnps = snps\n",
    "\n",
    "# make index matrix for each pair of bases. This assigns row / col number for full 16x16 matrix\n",
    "indexmat = np.array(range(16))\n",
    "indexmat.shape=(4,4)\n",
    "\n",
    "        # make 16x16 matrix of zeroes\n",
    "        # order across matrix is 00,01,02,03,10,11,12,13,20,21,22,23,30,31,32,33\n",
    "        # not good use of space\n",
    "fullmat0123 = np.zeros(shape=(16,16))\n",
    "arr0123 = finalsnps[:,possible_configs]\n",
    "for i in range(len(arr0123)):\n",
    "            # get row number \n",
    "    rownum = int(indexmat[arr0123[i][0:2][0],arr0123[i][0:2][1]])\n",
    "            # get col number\n",
    "    colnum = int(indexmat[arr0123[i][2:4][0],arr0123[i][2:4][1]])\n",
    "    fullmat0123[rownum,colnum] = fullmat0123[rownum,colnum] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the correct quartet configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = sess.run(y, feed_dict={x: [fullmat0123.flatten()/max(fullmat0123.flatten())]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 1, 3]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fourtaxa[i] for i in [[0,1,2,3],[0,2,1,3],[0,3,1,2]][int(tf.argmax(prediction,1).eval())]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now make a prediction for all quartets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltipcombns=list(itertools.combinations(range(37), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66045"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alltipcombns) # this is a lot. But we're tough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltipcombns = alltipcombns.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(alltipcombns) # maybe just in case we don't get all the way through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: The name 'Orn\\t37' looks like an (invalid) Operation name, not a Tensor. Tensor names must be of the form \"<op_name>:<output_index>\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-b1476ef7095b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mcolnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marr0123\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marr0123\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mfullmat0123\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrownum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolnum\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullmat0123\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrownum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolnum\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullmat0123\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullmat0123\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mallpredictedquarts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mallpredictedquarts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfourtaxa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallpredictedquarts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pmckenz1/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pmckenz1/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1069\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: '\n\u001b[0;32m-> 1071\u001b[0;31m                             + e.args[0])\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: The name 'Orn\\t37' looks like an (invalid) Operation name, not a Tensor. Tensor names must be of the form \"<op_name>:<output_index>\"."
     ]
    }
   ],
   "source": [
    "allpredictedquarts = np.array([]).reshape(0,4)\n",
    "for currentcombn in [alltipcombns[allcom] for allcom in range(18100,66045)]:\n",
    "    fourtaxa = np.array(currentcombn).astype(int)\n",
    "    genesnps = np.array([]).reshape(0,4)\n",
    "    for gene in range(1,447):\n",
    "        fname = \"download_simseqs/song-mammalian-bio_completely_processed/424genes/relabeled_data/\"+ str(gene) +\".fasta_relabeled.phy\"\n",
    "        if Path(fname).is_file():\n",
    "            raw = open(fname, 'r')\n",
    "            snps = file.read(raw) \n",
    "            snps = snps.split('\\n')\n",
    "            # remove whitespace characters like `\\n` at the end of each line\n",
    "            snps = [xs.strip() for xs in snps] \n",
    "            snps.pop(0)\n",
    "            [snps.pop(i) for i in range(len(snps)) if not len(snps[i])]\n",
    "\n",
    "            snps = [snps[i].split(\" \") for i in range(len(snps))]\n",
    "            snps = [filter(None, snps[i]) for i in range(len(snps))]\n",
    "\n",
    "            ids = [snps[i][0] for i in range(len(snps))]\n",
    "            sequences = [snps[i][1] for i in range(len(snps))]\n",
    "            fourfullseqs = [sequences[i] for i in fourtaxa]\n",
    "            snpseqs = np.array([]).reshape(0,4)\n",
    "            for q in range(len(fourfullseqs[0])):\n",
    "                current4bases=[fourfullseqs[i][q] for i in range(4)]\n",
    "                if ((len(set(current4bases).union(set(['A','G','C','T']))) == 4) and (len(set(current4bases)) > 1)):\n",
    "                    snpseqs = np.vstack([snpseqs, current4bases])\n",
    "            if len(snpseqs):\n",
    "                genesnps = np.vstack([genesnps,snpseqs[np.random.choice(len(snpseqs))]])\n",
    "\n",
    "    snps = np.array(genesnps)\n",
    "    possible_configs = [0,1,2,3]\n",
    "    snps = np.where(snps=='A',0,snps)\n",
    "    snps = np.where(snps=='C',1,snps)\n",
    "    snps = np.where(snps=='G',2,snps)\n",
    "    snps = np.where(snps=='T',3,snps)\n",
    "    snps = snps.astype(int)\n",
    "    finalsnps = snps\n",
    "\n",
    "    # make index matrix for each pair of bases. This assigns row / col number for full 16x16 matrix\n",
    "    indexmat = np.array(range(16))\n",
    "    indexmat.shape=(4,4)\n",
    "\n",
    "            # make 16x16 matrix of zeroes\n",
    "            # order across matrix is 00,01,02,03,10,11,12,13,20,21,22,23,30,31,32,33\n",
    "            # not good use of space\n",
    "    fullmat0123 = np.zeros(shape=(16,16))\n",
    "    arr0123 = finalsnps[:,possible_configs]\n",
    "    for i in range(len(arr0123)):\n",
    "                # get row number \n",
    "        rownum = int(indexmat[arr0123[i][0:2][0],arr0123[i][0:2][1]])\n",
    "                # get col number\n",
    "        colnum = int(indexmat[arr0123[i][2:4][0],arr0123[i][2:4][1]])\n",
    "        fullmat0123[rownum,colnum] = fullmat0123[rownum,colnum] + 1\n",
    "    prediction = sess.run(y, feed_dict={x: [(fullmat0123.flatten()/max(fullmat0123.flatten()))]})\n",
    "    allpredictedquarts = np.vstack([allpredictedquarts,[fourtaxa[i] for i in [[0,1,2,3],[0,2,1,3],[0,3,1,2]][int(tf.argmax(prediction,1).eval())]]])\n",
    "    print(len(allpredictedquarts))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3870"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allpredictedquarts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14.,  29.,  33.,  34.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltipcombns[4830]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66044"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(4830,66045)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allpredictedquarts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = np.loadtxt(\"download_simseqs/mammal_quarts.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18100"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltipcombns = np.loadtxt(\"download_simseqs/combn_order.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.savetxt(\"download_simseqs/mammal_quarts.gz\",np.vstack([test,allpredictedquarts]))\n",
    "#np.savetxt(\"download_simseqs/combn_order.gz\",alltipcombns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mac',\n",
       " 'New',\n",
       " 'Sor',\n",
       " 'Gor',\n",
       " 'Oto',\n",
       " 'Spe',\n",
       " 'Ory',\n",
       " 'Tup',\n",
       " 'Dip',\n",
       " 'Tur',\n",
       " 'Mic',\n",
       " 'Eri',\n",
       " 'Och',\n",
       " 'Lox',\n",
       " 'Fel',\n",
       " 'Tar',\n",
       " 'Pro',\n",
       " 'Ech',\n",
       " 'Das',\n",
       " 'Myo',\n",
       " 'Mus',\n",
       " 'Rat',\n",
       " 'Cav',\n",
       " 'Cho',\n",
       " 'Bos',\n",
       " 'Cal',\n",
       " 'Pon',\n",
       " 'Hom',\n",
       " 'Pan',\n",
       " 'Sus',\n",
       " 'Vic',\n",
       " 'Can',\n",
       " 'Pte',\n",
       " 'Equ',\n",
       " 'Gal',\n",
       " 'Mon',\n",
       " 'Orn']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"download_simseqs/song-mammalian-bio_completely_processed/taxa_dict.txt\") as f:\n",
    "    test = f.readlines()\n",
    "test = [x.strip() for x in test]\n",
    "nameskey = [test[i].split(\"\\t\") for i in range(len(test))]\n",
    "[i[0] for i in nameskey] # this gives just the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpredictedquarts = np.loadtxt(\"download_simseqs/mammal_quarts.gz\")\n",
    "allpredictedquarts = allpredictedquarts.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dump_qmc(quartets = allpredictedquarts,tempfiledir= \"download_simseqs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "_run_qmc(tempfiledir = \"download_simseqs/\", \n",
    "         tempfilename=\"download_simseqs/quartets.txt\",\n",
    "         treename=\"tree4830.phy\",\n",
    "         tipnames=[i[0] for i in nameskey])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
