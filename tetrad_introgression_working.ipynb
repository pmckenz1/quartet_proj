{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox document for getting Hils results via Tetrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipyrad as ip\n",
    "import ipyrad.analysis as ipa\n",
    "import toytree \n",
    "import h5py\n",
    "import ipyparallel as ipp\n",
    "import numpy as np\n",
    "import math\n",
    "## ipcluster start -n20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## conda install ipyrad -c ipyrad\n",
    "## conda install toytree -c eaton-lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip 0.7.14\n",
      "toytree 0.1.4\n"
     ]
    }
   ],
   "source": [
    "## up-to-date versions \n",
    "print 'ip', ipa.__version__\n",
    "print 'toytree', toytree.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Assembly: pedicularis\n",
      "0   assembly_name               pedicularis                                  \n",
      "1   project_dir                 ./analysis-ipyrad                            \n",
      "2   raw_fastq_path                                                           \n",
      "3   barcodes_path                                                            \n",
      "4   sorted_fastq_path           ./fastqs-Ped/*.fastq.gz                      \n",
      "5   assembly_method             denovo                                       \n",
      "6   reference_sequence                                                       \n",
      "7   datatype                    rad                                          \n",
      "8   restriction_overhang        ('TGCAG', '')                                \n",
      "9   max_low_qual_bases          5                                            \n",
      "10  phred_Qscore_offset         33                                           \n",
      "11  mindepth_statistical        6                                            \n",
      "12  mindepth_majrule            6                                            \n",
      "13  maxdepth                    10000                                        \n",
      "14  clust_threshold             0.9                                          \n",
      "15  max_barcode_mismatch        0                                            \n",
      "16  filter_adapters             2                                            \n",
      "17  filter_min_trim_len         35                                           \n",
      "18  max_alleles_consens         2                                            \n",
      "19  max_Ns_consens              (5, 5)                                       \n",
      "20  max_Hs_consens              (5, 5)                                       \n",
      "21  min_samples_locus           4                                            \n",
      "22  max_SNPs_locus              (20, 20)                                     \n",
      "23  max_Indels_locus            (8, 8)                                       \n",
      "24  max_shared_Hs_locus         0.5                                          \n",
      "25  trim_reads                  (0, 0, 0, 0)                                 \n",
      "26  trim_loci                   (0, 5, 0, 0)                                 \n",
      "27  output_formats              ('p', 's', 'v', 'n', 'k', 'u', 'a')          \n",
      "28  pop_assign_file                                                          \n",
      "Assembly: pedicularis\n",
      "[####################] 100%  loading reads         | 0:00:33 | s1 | \n",
      "[                    ]   0%  processing reads      | 0:04:28 | s2 | \n",
      "  Keyboard Interrupt by user\n",
      "Assembly: pedicularis\n",
      "\n",
      "  Encountered an unexpected error (see ./ipyrad_log.txt)\n",
      "  Error message is below -------------------------------\n",
      "    No Samples ready to be clustered. First run step 2.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "data = ip.Assembly(\"pedicularis\")\n",
    "## set parameters\n",
    "data.set_params(\"project_dir\", \"analysis-ipyrad\")\n",
    "data.set_params(\"sorted_fastq_path\", \"fastqs-Ped/*.fastq.gz\")\n",
    "data.set_params(\"clust_threshold\", \"0.90\")\n",
    "data.set_params(\"filter_adapters\", \"2\")\n",
    "data.set_params(\"max_Hs_consens\", (5, 5))\n",
    "data.set_params(\"trim_loci\", (0, 5, 0, 0))\n",
    "data.set_params(\"output_formats\", \"psvnkua\")\n",
    "\n",
    "## see/print all parameters\n",
    "data.get_params()\n",
    "## run steps 1 & 2 of the assembly\n",
    "data.run(\"12\")\n",
    "## run steps 3-6 of the assembly\n",
    "data.run(\"3456\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pops = data.branch(\"min11-pops\")\n",
    "pops.populations = {\n",
    "    \"ingroup\": (11, [i for i in pops.samples if \"prz\" not in i]),\n",
    "    \"outgroup\" : (0, [i for i in pops.samples if \"prz\" in i]),\n",
    "    }\n",
    "pops.run(\"7\")\n",
    "\n",
    "## create a branch with no missing data and with outgroups removed\n",
    "nouts = data.branch(\"nouts_min11\", subsamples=[i for i in pops.samples if \"prz\" not in i])\n",
    "nouts.set_params(\"min_samples_locus\", 11)\n",
    "nouts.run(\"7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Assembly: min4\n",
      "from saved path: ~/Desktop/projects/intro_python/analysis-ipyrad/min4.json\n"
     ]
    }
   ],
   "source": [
    "data = ip.load_json(\"/Users/pmckenz1/Desktop/projects/quartet_proj/analysis-ipyrad/min4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading seq array [13 taxa x 173131 bp]\n",
      "max unlinked SNPs per quartet (nloci): 39634\n"
     ]
    }
   ],
   "source": [
    "## init a tetrad analysis object\n",
    "tet = ipa.tetrad(\n",
    "    name=data.name,\n",
    "    data=data.outfiles.snpsphy,\n",
    "    mapfile=data.outfiles.snpsmap,\n",
    "    nboots=10,\n",
    "    save_invariants=True   ## <- new option to save the arrays\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipyclient = ipp.Client()\n",
    "ipyclient.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferring 715 quartet tree sets\n",
      "host compute node: [20 cores] on Patricks-MacBook-Pro.local\n",
      "[####################] 100% generating q-sets | 0:00:00 |  \n",
      "[####################] 100% initial tree      | 0:00:01 |  \n",
      "[####################] 100% bootstrap trees   | 0:00:11 |  \n",
      "[####################] 100% calculating stats | 0:00:01 |  \n"
     ]
    }
   ],
   "source": [
    "tet.run(ipyclient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferred quartet: [0 2 1 3]\n",
      "matrix for ordered set:\n",
      "[[  0 145 557 251  16   3   0   1  60   1  12   0  25   0   0   0]\n",
      " [ 42  26   1   2   3  42   0   1   0   0   1   0   0   1   0   0]\n",
      " [155   1  75   2   0   0   0   0  12   0 106   1   0   0   1   0]\n",
      " [ 65   0   0  15   0   0   0   1   0   0   0   0   1   0   1  30]\n",
      " [ 16   0   0   1   8  68   1   3   0   0   0   0   0   0   0   0]\n",
      " [  2  35   1   2 157   0 112 481   0  21   3   2   2 111   1   8]\n",
      " [  0   0   0   0   0  46  13   2   0   1  11   0   0   0   0   0]\n",
      " [  0   1   0   0   4 201   7  70   0   0   0   0   0   9   1  68]\n",
      " [ 49   0  10   2   1   0   0   0  55   3 189   2   0   0   0   0]\n",
      " [  0   0   0   0   0  24   0   1   2  11  32   0   0   0   0   0]\n",
      " [  9   1  99   1   0   1  15   0 496 118   0 129   0   1  39   0]\n",
      " [  0   0   2   0   0   0   0   0   3   3  71  11   0   1   2  17]\n",
      " [ 42   0   0   3   0   3   0   0   0   0   0   0  26   1   3  51]\n",
      " [  0   0   0   0   0 127   0  10   0   0   0   0   1  56   2 113]\n",
      " [  0   0   1   0   0   1   0   0   3   0  43   1   1   2  28  31]\n",
      " [  1   1   0  17   1   6   0  61   0   0   3  16 275 519 134   0]]\n"
     ]
    }
   ],
   "source": [
    "## a 16x16 matrix for one quartet\n",
    "with h5py.File(tet.database.output) as db:\n",
    "    idx = 0\n",
    "    qrt = db['quartets'][idx]\n",
    "    arr = db['invariants/boot0']\n",
    "    print 'inferred quartet:', qrt\n",
    "    print 'matrix for ordered set:\\n', arr[idx, :, :]\n",
    "    \n",
    "with h5py.File(tet.database.output) as db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = h5py.File(tet.database.output, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Parental taxa are more closely related than hybrid. Discard this.',\n",
       " '0.401917492623',\n",
       " '0.397271047622']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = f['invariants']['boot0'][0]\n",
    "\n",
    "mats = np.zeros((3, 16, 16), dtype=np.uint32)\n",
    "mats[0] = arr\n",
    "x = np.uint8(0)\n",
    "for y in np.array([0, 4, 8, 12], dtype=np.uint8):\n",
    "    for z in np.array([0, 4, 8, 12], dtype=np.uint8):\n",
    "        mats[1, y:y+np.uint8(4), z:z+np.uint8(4)] = mats[0, x].reshape(4, 4)\n",
    "        #mats[2, y:y+np.uint8(4), z:z+np.uint8(4)] = mats[0, x].reshape(4, 4).T\n",
    "        x += np.uint8(1)\n",
    "x = np.uint8(0)\n",
    "for z in np.array([0,1,2,3]):\n",
    "    for y in np.array([0,4,8,12]):\n",
    "        mats[2,:,x] = mats[0,:,(y+z)]\n",
    "        x += np.uint8(1)\n",
    "\n",
    "[calcHils(mats[0]),calcHils(mats[1]),calcHils(mats[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Hils(object):\n",
    "    \"\"\"\n",
    "    A Class to calculate the Hils statistic given a matrix of invariants.\n",
    "    \"\"\"\n",
    "    def __init__(self, database, boot=0):\n",
    "        ## open file handles for accessing database\n",
    "        self._open = True\n",
    "        self._boot = boot\n",
    "        self.hdf5 = h5py.File(database)\n",
    "        self.matrix = self.hdf5[\"invariants\"]\n",
    "        self.quartets = self.hdf5[\"quartets\"]\n",
    "        self.nquartets = self.quartets.shape[0]\n",
    "    \n",
    "    \n",
    "    def close_db(self):\n",
    "        \"\"\"close the database file\"\"\"\n",
    "        self.hdf5.close()\n",
    "    \n",
    "    \n",
    "    def get_counts_by_idx(self, idx):\n",
    "        \"\"\"return site counts for a given index (quartet)\"\"\"\n",
    "        ## get matrix\n",
    "        mat = self.matrix[\"boot{}\".format(self._boot)][idx, :, :]\n",
    "        qrt = self.quartets[idx]\n",
    "        \n",
    "        ## arrange matrix\n",
    "        if qrt[1] > qrt[3]:\n",
    "            mat = alt_mats(mat, 2)\n",
    "        elif qrt[1] > qrt[2]:\n",
    "            mat = alt_mats(mat, 1)\n",
    "            \n",
    "        ## get counts and format\n",
    "        df = pd.DataFrame(\n",
    "            data=count_snps(mat), \n",
    "            index=[\"aabb\", \"abba\", \"baba\", \"aaab\"], \n",
    "            columns=[idx]).T\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def get_h_by_idx(self, idx):\n",
    "        \"\"\"\n",
    "        calculate Hils. This could be numba-fied, but you'd have to work\n",
    "        with arrays instead of dataframes. This is fine for now.\n",
    "        \"\"\"\n",
    "        ## get site frequencies\n",
    "        df = self.get_counts_by_idx(idx)\n",
    "        nsites = df.sum(axis=1).values[0]\n",
    "        pdf = df/nsites\n",
    "        pdf.columns = [\"p\"+i for i in df.columns]\n",
    "        data = pd.concat([df, pdf], axis=1)\n",
    "        \n",
    "        ## choose invariant pattern\n",
    "        f1 = data.paabb - data.pbaba\n",
    "        f2 = data.pabba - data.pbaba\n",
    "        ratio = f1 / f2\n",
    "        \n",
    "        ## calculate var, covar\n",
    "        var_f1 = (1. / nsites) * (\n",
    "                    data.paabb * (1. - data.paabb) \\\n",
    "                  + data.pbaba * (1. - data.pbaba) \\\n",
    "                  + 2. * data.paabb * data.pbaba)\n",
    "\n",
    "        var_f2 = (1. / nsites) * (\n",
    "                    data.pabba * (1. - data.pabba) \\\n",
    "                  + data.pbaba * (1. - data.pbaba) \\\n",
    "                  + 2. * data.pabba * data.pbaba)\n",
    "\n",
    "        cov_f1_f2 = (1. / nsites) * (\n",
    "                   -data.paabb * data.pabba \\\n",
    "                  + data.paabb * data.pbaba \\\n",
    "                  + data.pabba * data.pbaba \\\n",
    "                  + data.pbaba * (1. - data.pbaba))\n",
    "\n",
    "        ## calculate hils\n",
    "        num = abs(f2 * ratio)\n",
    "        denom = np.sqrt(var_f2 * (ratio**2) - (2 * cov_f1_f2 * ratio + var_f1))\n",
    "        H = pd.DataFrame({\"Hils\":num/denom, \"gamma\":(f1/f1+f2)}, index=[idx])\n",
    "\n",
    "        data = pd.concat([df, pdf, H], axis=1)\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"calculate Hils and return table for all idxs in database\"\"\"\n",
    "        stats = pd.concat([self.get_h_by_idx(idx) for idx in xrange(self.nquartets)])\n",
    "        qrts = [\"{},{}|{},{}\".format(*i) for i in self.quartets[:]]\n",
    "        qrts = pd.DataFrame(np.array(qrts), columns=[\"qrts\"])\n",
    "        return pd.concat([stats, qrts], axis=1)\n",
    "    \n",
    "    \n",
    "@numba.jit(nopython=True)   \n",
    "def alt_mats(mat, idx):\n",
    "    \"\"\" return alternate rearrangement of matrix\"\"\"\n",
    "    mats = np.zeros((3, 16, 16), dtype=np.uint32)\n",
    "    mats[0] = arr\n",
    "    x = np.uint8(0)\n",
    "    for y in np.array([0, 4, 8, 12], dtype=np.uint8):\n",
    "        for z in np.array([0, 4, 8, 12], dtype=np.uint8):\n",
    "            mats[1, y:y+np.uint8(4), z:z+np.uint8(4)] = mats[0, x].reshape(4, 4)\n",
    "            mats[2, y:y+np.uint8(4), z:z+np.uint8(4)] = mats[0, x].reshape(4, 4).T\n",
    "            x += np.uint8(1)\n",
    "    return mats[idx]\n",
    "        \n",
    "        \n",
    "@numba.jit(nopython=True)\n",
    "def count_snps(mat):\n",
    "    \"\"\"JIT func to return counts quickly\"\"\"\n",
    "    ## array to store results\n",
    "    snps = np.zeros(4, dtype=np.uint16)\n",
    "\n",
    "    ## get concordant (aabb) pis sites\n",
    "    snps[0] = np.uint16(\\\n",
    "           mat[0, 5] + mat[0, 10] + mat[0, 15] + \\\n",
    "           mat[5, 0] + mat[5, 10] + mat[5, 15] + \\\n",
    "           mat[10, 0] + mat[10, 5] + mat[10, 15] + \\\n",
    "           mat[15, 0] + mat[15, 5] + mat[15, 10])\n",
    "\n",
    "    ## get discordant (baba) sites\n",
    "    for i in range(16):\n",
    "        if i % 5:\n",
    "            snps[1] += mat[i, i]\n",
    "\n",
    "    ## get discordant (abba) sites\n",
    "    snps[2] = mat[1, 4] + mat[2, 8] + mat[3, 12] +\\\n",
    "              mat[4, 1] + mat[6, 9] + mat[7, 13] +\\\n",
    "              mat[8, 2] + mat[9, 6] + mat[11, 14] +\\\n",
    "              mat[12, 3] + mat[13, 7] + mat[14, 11]\n",
    "\n",
    "    ## get autapomorphy sites\n",
    "    snps[3] = (mat.sum() - np.diag(mat).sum()) - snps[2]\n",
    "    return snps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcHils(invmat, Nreq = 10, returnf = False, returnp = False, returnall = False,returnnum = False):\n",
    "    invmat = invmat.astype(float)\n",
    "    comb_dict = dict(zip([00,01,02,03,10,11,12,13,20,21,22,23,30,31,32,33], [0,  1,  2,  3,  4,  5,  6,  7,  8,  9,  10, 11, 12, 13, 14, 15]))\n",
    "    num_iijj = (invmat[comb_dict[00],comb_dict[11]] + invmat[comb_dict[00],comb_dict[22]] +\n",
    "        invmat[comb_dict[00],comb_dict[33]] + invmat[comb_dict[11],comb_dict[00]] + invmat[comb_dict[11],comb_dict[22]] +\n",
    "        invmat[comb_dict[11],comb_dict[33]] + invmat[comb_dict[22],comb_dict[00]] + invmat[comb_dict[22],comb_dict[11]] +\n",
    "        invmat[comb_dict[22],comb_dict[33]] + invmat[comb_dict[33],comb_dict[00]] + invmat[comb_dict[33],comb_dict[11]] +\n",
    "        invmat[comb_dict[33],comb_dict[22]])\n",
    "\n",
    "    num_ijji = (invmat[comb_dict[01],comb_dict[10]] + invmat[comb_dict[02],comb_dict[20]] +\n",
    "        invmat[comb_dict[03],comb_dict[30]] + invmat[comb_dict[10],comb_dict[01]] + invmat[comb_dict[12],comb_dict[21]] +\n",
    "        invmat[comb_dict[13],comb_dict[31]] + invmat[comb_dict[20],comb_dict[02]] + invmat[comb_dict[21],comb_dict[12]] +\n",
    "        invmat[comb_dict[23],comb_dict[32]] + invmat[comb_dict[30],comb_dict[03]] + invmat[comb_dict[31],comb_dict[13]] +\n",
    "        invmat[comb_dict[32],comb_dict[23]])\n",
    "\n",
    "    num_ijij = (invmat[comb_dict[01],comb_dict[01]] + invmat[comb_dict[02],comb_dict[02]] +\n",
    "        invmat[comb_dict[03],comb_dict[03]] + invmat[comb_dict[10],comb_dict[10]] + invmat[comb_dict[12],comb_dict[12]] +\n",
    "        invmat[comb_dict[13],comb_dict[13]] + invmat[comb_dict[20],comb_dict[20]] + invmat[comb_dict[21],comb_dict[21]] +\n",
    "        invmat[comb_dict[23],comb_dict[23]] + invmat[comb_dict[30],comb_dict[30]] + invmat[comb_dict[31],comb_dict[31]] +\n",
    "        invmat[comb_dict[32],comb_dict[32]])\n",
    "    [num_iijj,num_ijji,num_ijij]\n",
    "    if (num_ijij == 0 and num_ijji == 0):\n",
    "        return(\"No ijij or ijji are present in data (not enough data)\")\n",
    "    N = sum(map(sum, invmat))\n",
    "    if (N <= Nreq):\n",
    "        return(\"Not enough snps.\")\n",
    "    # calculate probability, add .05 to counts in case some of them are 0\n",
    "    p_iijj = (num_iijj + .05)/N\n",
    "    p_ijji = (num_ijji + .05)/N\n",
    "    p_ijij = (num_ijij + .05)/N\n",
    "    \n",
    "    if (p_ijij > max([p_iijj,p_ijji])):\n",
    "        return(\"Parental taxa are more closely related than hybrid. Discard this.\")\n",
    "    \n",
    "    f1 = p_iijj - p_ijij\n",
    "    f2 = p_ijji - p_ijij\n",
    "    if not(f2):\n",
    "        p_ijji = (num_ijji + 1. + .05)/N\n",
    "        f2 = p_ijji - p_ijij\n",
    "    rat_f1_f2 = f1/f2\n",
    "\n",
    "    var_f1 = (1./N) * ( p_iijj*(1.-p_iijj) + p_ijij*(1.-p_ijij) + 2.*p_iijj*p_ijij )\n",
    "    var_f2 = (1./N) * ( p_ijji*(1.-p_ijji) + p_ijij*(1.-p_ijij) + 2.*p_ijji*p_ijij )\n",
    "\n",
    "    cov_f1_f2 = (1./N) * ( -p_iijj*p_ijji + p_iijj*p_ijij + p_ijji*p_ijij + p_ijij*(1.-p_ijij))\n",
    "\n",
    "    H = abs(f2 * rat_f1_f2) / math.sqrt( var_f2*(rat_f1_f2**2.) - 2.*cov_f1_f2*rat_f1_f2 + var_f1 )\n",
    "    if returnf:\n",
    "        return [H, f1, f2];\n",
    "    if returnp:\n",
    "        return [H, p_iijj,p_ijji,p_ijij];\n",
    "    if returnall:\n",
    "        return [H, f1, f2, p_iijj,p_ijji,p_ijij];\n",
    "    if returnnum:\n",
    "        return [num_iijj,num_ijji,num_ijij];\n",
    "    if(num_ijij-num_ijji == 0):\n",
    "        return('*'+str(H))\n",
    "    else:\n",
    "        return str(H);\n",
    "def calcp(z):\n",
    "    p = st.norm.sf(abs(z))*2\n",
    "    return p;\n",
    "def isfloat(value):\n",
    "  try:\n",
    "    float(value)\n",
    "    return True\n",
    "  except ValueError:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Parental taxa are more closely related than hybrid. Discard this.',\n",
       " '0.401917492623',\n",
       " '0.397271047622']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = f['invariants']['boot0'][0]\n",
    "\n",
    "\n",
    "mats = np.zeros((3, 16, 16), dtype=np.uint32)\n",
    "mats[0] = arr\n",
    "x = np.uint8(0)\n",
    "for y in np.array([0, 4, 8, 12], dtype=np.uint8):\n",
    "    for z in np.array([0, 4, 8, 12], dtype=np.uint8):\n",
    "        mats[1, y:y+np.uint8(4), z:z+np.uint8(4)] = mats[0, x].reshape(4, 4)\n",
    "        #mats[2, y:y+np.uint8(4), z:z+np.uint8(4)] = mats[0, x].reshape(4, 4).T\n",
    "        x += np.uint8(1)\n",
    "x = np.uint8(0)\n",
    "for z in np.array([0,1,2,3]):\n",
    "    for y in np.array([0,4,8,12]):\n",
    "        mats[2,:,x] = mats[0,:,(y+z)]\n",
    "        x += np.uint8(1)\n",
    "\n",
    "[calcHils(mats[0]),calcHils(mats[1]),calcHils(mats[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6108"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(mats[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  79, 235,  96,  55,   2,   0,   1, 213,   1,   5,   0, 106,\n",
       "         1,   0,   1], dtype=uint32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mats[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "mats = np.zeros((3, 16, 16), dtype=np.uint32)\n",
    "mats[0] = arr\n",
    "x = np.uint8(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  55, 211,  82],\n",
       "       [ 65,   3,   1,   0],\n",
       "       [219,   0,  12,   1],\n",
       "       [ 90,   0,   0,   2]], dtype=uint32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mats[0,0].reshape(4,4).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
