{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dump_qmc(quartets,tempfiledir):\n",
    "    \"\"\"\n",
    "    Writes the inferred quartet sets from the database to a text \n",
    "    file to be used as input for QMC. Quartets that had no information\n",
    "    available (i.e., no SNPs) were written to the database as 0,0,0,0\n",
    "    and are excluded here from the output.\n",
    "    \"\"\"\n",
    "\n",
    "    ## open the h5 database\n",
    "    #with h5py.File(self.database.output, 'r') as io5:\n",
    "\n",
    "        ## create an output file for writing\n",
    "    tempfile = os.path.join(tempfiledir,\"quartets.txt\")\n",
    "    with open(tempfile, 'w') as qdump:\n",
    "\n",
    "        ## pull from db\n",
    "        #for idx in xrange(0, self.params.nquartets, self._chunksize):\n",
    "            #quarts = quartets\n",
    "\n",
    "            ## shuffle and format for qmc\n",
    "            #np.random.shuffle(quarts)\n",
    "            chunk = [\"{},{}|{},{}\".format(*i) for i in quartets]\n",
    "            qdump.write(\"\\n\".join(chunk)+\"\\n\")\n",
    "\n",
    "\n",
    "def _run_qmc(tempfiledir, tempfilename,treename,tipnames):\n",
    "    \"\"\"\n",
    "    Runs quartet max-cut QMC on the quartets qdump file.\n",
    "    \"\"\"\n",
    "\n",
    "    ## build command\n",
    "    thetmptree = os.path.join(tempfiledir, \"tmptre.phy\")\n",
    "    cmd = [ip.bins.qmc, \"qrtt=\"+tempfilename, \"otre=\"+thetmptree]\n",
    "\n",
    "    ## run it\n",
    "    proc = subprocess.Popen(cmd, stderr=subprocess.STDOUT, stdout=subprocess.PIPE)\n",
    "    res = proc.communicate()\n",
    "    #if proc.returncode:\n",
    "    #    print(proc.returncode)\n",
    "    #    raise IPyradWarningExit(res[1])\n",
    "\n",
    "    ## parse tmp file written by qmc into a tree and rename it\n",
    "    with open(thetmptree, 'r') as intree:\n",
    "        tre = ete3.Tree(intree.read().strip())\n",
    "        names = tre.get_leaves()\n",
    "        for name in names:\n",
    "            name.name = tipnames[(int(name.name)-1)]\n",
    "        tmptre = tre.write(format=9)\n",
    "\n",
    "    ## save the tree to file\n",
    "    #if boot:\n",
    "    #    self.trees.boots = os.path.join(self.dirs, self.name+\".boots\")\n",
    "    #    with open(self.trees.boots, 'a') as outboot:\n",
    "    #        outboot.write(tmptre+\"\\n\")\n",
    "    #else:\n",
    "    treepath  = os.path.join(tempfiledir, treename+\".tree\")\n",
    "    with open(treepath, 'w') as outtree:\n",
    "        outtree.write(tmptre)\n",
    "\n",
    "    ## save the file\n",
    "    #treepath._save()\n",
    "#@contextlib.contextmanager\n",
    "#def nostdout():\n",
    "#    save_stdout = sys.stdout\n",
    "#    sys.stdout = io.BytesIO()\n",
    "#    yield\n",
    "#    sys.stdout = save_stdout\n",
    "\n",
    "def run_mammal_inf(totalseqs_path,\n",
    "                     snpmap_path,\n",
    "                     output_path,\n",
    "                     writing_interval = 200,\n",
    "                     starting_combo = 0\n",
    "                    ):\n",
    "    totalseqs = np.genfromtxt(totalseqs_path,dtype='str')\n",
    "    snpmap = np.loadtxt(snpmap_path).astype(int)\n",
    "\n",
    "    alltipcombns=np.array(list(itertools.combinations(range(len(totalseqs[0])), 4)))\n",
    "    alltipcombns = alltipcombns.astype(int)\n",
    "\n",
    "    genes_alltaxa = [totalseqs[snpmap[0][i]:snpmap[1][i]] for i in range(len(snpmap[0]))]\n",
    "\n",
    "    if not starting_combo:\n",
    "        combocounter = 0\n",
    "        orig_file = np.empty(shape = (0,4))\n",
    "        np.savetxt(output_path,orig_file)\n",
    "    else:\n",
    "        combocounter = starting_combo\n",
    "    targetlen = len(alltipcombns)\n",
    "\n",
    "    # the first time you run this, run the next two lines to make a new file:\n",
    "\n",
    "    #orig_file = np.empty(shape = (0,4))\n",
    "    #np.savetxt(\"download_simseqs/mammal_quarts.txt\",orig_file)\n",
    "\n",
    "    while combocounter < (targetlen -1):\n",
    "        allpredictedquarts = np.empty(shape = (0,4))\n",
    "        savecounter = 0 # this will be reset\n",
    "        while (savecounter < writing_interval) and (combocounter < (targetlen)):\n",
    "            # set your current combination of four taxa\n",
    "            fourtaxa= alltipcombns[combocounter]\n",
    "\n",
    "            # get one snp at each locus -- might eventually be better to build a distribution at each locus, or \n",
    "            # at least compare quality of inference done both ways\n",
    "\n",
    "            # before, I'd been getting all informative, complete SNPs at each locus and then randomly selecting. \n",
    "            # Much more efficient this way, shuffling each locus randomly and then selecting first informative SNP\n",
    "\n",
    "            reducedgene = np.empty(shape = (0,4))\n",
    "            for geneidx in range(len(genes_alltaxa)):\n",
    "                currentgene = genes_alltaxa[geneidx]\n",
    "                orderedsamples = range(len(currentgene))\n",
    "                np.random.shuffle(orderedsamples)\n",
    "                trigger = 0\n",
    "                q = 0\n",
    "                while (trigger == 0) and (q < (len(currentgene)-1)):\n",
    "                    currentgene = [genes_alltaxa[geneidx][orderedsamples[q]][taxon] for taxon in fourtaxa]\n",
    "                    q += 1\n",
    "                    if ((len(set(currentgene).union(set(['A','G','C','T']))) == 4) and (len(set(currentgene)) > 1)):\n",
    "                        reducedgene = np.vstack([reducedgene,currentgene])\n",
    "                        trigger = 1\n",
    "\n",
    "            arr0123 = np.array(reducedgene)\n",
    "            possible_configs = [[0,1,2,3],[0,2,1,3],[0,3,1,2]]\n",
    "            arr0123 = np.where(arr0123=='A',0,arr0123)\n",
    "            arr0123 = np.where(arr0123=='C',1,arr0123)\n",
    "            arr0123 = np.where(arr0123=='G',2,arr0123)\n",
    "            arr0123 = np.where(arr0123=='T',3,arr0123)\n",
    "            arr0123 = arr0123.astype(int)\n",
    "\n",
    "            # make index matrix for each pair of bases. This assigns row / col number for full 16x16 matrix\n",
    "            indexmat = np.array(range(16))\n",
    "            indexmat.shape=(4,4)\n",
    "\n",
    "                    # make 16x16 matrix of zeroes\n",
    "                    # order across matrix is 00,01,02,03,10,11,12,13,20,21,22,23,30,31,32,33\n",
    "                    # not good use of space\n",
    "            three_possible = []\n",
    "            for q in possible_configs:\n",
    "                temp_rearrangement = arr0123[:,q]\n",
    "                fullmat0123 = np.zeros(shape=(16,16))\n",
    "                for i in range(len(temp_rearrangement)):\n",
    "                            # get row number \n",
    "                    rownum = int(indexmat[temp_rearrangement[i][0:2][0],temp_rearrangement[i][0:2][1]])\n",
    "                            # get col number\n",
    "                    colnum = int(indexmat[temp_rearrangement[i][2:4][0],temp_rearrangement[i][2:4][1]])\n",
    "                    fullmat0123[rownum,colnum] = fullmat0123[rownum,colnum] + 1\n",
    "                three_possible.append((fullmat0123.flatten()/max(fullmat0123.flatten())))\n",
    "            # comment this as TEST\n",
    "            #prediction = sess.run(y, feed_dict={x: [(fullmat0123.flatten()/max(fullmat0123.flatten()))]})\n",
    "            tf.reset_default_graph()\n",
    "            x = tf.placeholder(tf.float32, [None, 256])\n",
    "            W = tf.Variable(tf.zeros([256, 2]))\n",
    "            b = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "            y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "            y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "            # Add ops to save and restore all the variables.\n",
    "            saver = tf.train.Saver()\n",
    "            # Later, launch the model, use the saver to restore variables from disk, and\n",
    "            # do some work with the model.\n",
    "            with tf.Session() as sess:\n",
    "                # Restore variables from disk.\n",
    "#                with nostdout():\n",
    "                saver.restore(sess, \"download_simseqs/saved_mo.ckpt\")\n",
    "                #print(\"Model restored.\")\n",
    "                predictions = sess.run(y, feed_dict={x: three_possible[0:3]})\n",
    "#                prediction = predictions[0];\n",
    "            \n",
    "            #print(str(savecounter) +\" \" + str(combocounter))\n",
    "            \n",
    "            savecounter += 1\n",
    "            combocounter += 1\n",
    "            print predictions\n",
    "            maxval = max([predictions[i][0] for i in range(len(predictions))])\n",
    "            max_index = [predictions[i][0] for i in range(len(predictions))].index(maxval)\n",
    "#            print max_index\n",
    "            allpredictedquarts = np.vstack([allpredictedquarts,np.array([fourtaxa[i] for i in [[0,1,2,3],[0,2,1,3],[0,3,1,2]][max_index]]).astype(int)])\n",
    "#            print np.array([fourtaxa[i] for i in [[0,1,2,3],[0,2,1,3],[0,3,1,2]][max_index]]).astype(int)\n",
    "        f_handle = file(output_path,\"a\")\n",
    "        np.savetxt(f_handle,allpredictedquarts.astype(int))\n",
    "        f_handle.close()\n",
    "#            print [fourtaxa[i] for i in [[0,1,2,3],[0,2,1,3],[0,3,1,2]][max_index]]\n",
    "    return;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_mammal_inf(totalseqs_path = \"download_simseqs/concat_mammal_genes.gz\",\n",
    "                 snpmap_path = \"download_simseqs/concat_mammal_map.gz\",\n",
    "                 output_path = \"download_simseqs/testingfunc.txt\",\n",
    "                 writing_interval = 200,\n",
    "                 starting_combo = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allpredictedquarts = np.loadtxt(\"download_simseqs/testingfunc.txt\")\n",
    "with open(\"download_simseqs/song-mammalian-bio_completely_processed/taxa_dict.txt\") as f:\n",
    "    test = f.readlines()\n",
    "test = [x.strip() for x in test]\n",
    "nameskey = [test[i].split(\"\\t\") for i in range(len(test))]\n",
    "dump_qmc(quartets = (allpredictedquarts.astype(int)+1),tempfiledir= \"download_simseqs/\")\n",
    "_run_qmc(tempfiledir = \"download_simseqs/\", \n",
    "         tempfilename=\"download_simseqs/quartets.txt\",\n",
    "         treename=\"treeFULLagain.phy\",\n",
    "         tipnames=[i[0] for i in nameskey])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I think this is outdated..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_mammal_quarts(totalseqs_path,\n",
    "                     snpmap_path,\n",
    "                     output_path,\n",
    "                     writing_interval = 200,\n",
    "                     starting_combo = 0\n",
    "                    ):\n",
    "    totalseqs = np.genfromtxt(totalseqs_path,dtype='str')\n",
    "    snpmap = np.loadtxt(snpmap_path).astype(int)\n",
    "\n",
    "    alltipcombns=np.array(list(itertools.combinations(range(len(totalseqs[0])), 4)))\n",
    "    alltipcombns = alltipcombns.astype(int)\n",
    "\n",
    "    genes_alltaxa = [totalseqs[snpmap[0][i]:snpmap[1][i]] for i in range(len(snpmap[0]))]\n",
    "\n",
    "    if not starting_combo:\n",
    "        combocounter = 0\n",
    "        orig_file = np.empty(shape = (0,4))\n",
    "        np.savetxt(output_path,orig_file)\n",
    "    else:\n",
    "        combocounter = starting_combo\n",
    "    targetlen = len(alltipcombns)\n",
    "\n",
    "    # the first time you run this, run the next two lines to make a new file:\n",
    "\n",
    "    #orig_file = np.empty(shape = (0,4))\n",
    "    #np.savetxt(\"download_simseqs/mammal_quarts.txt\",orig_file)\n",
    "\n",
    "\n",
    "    allpredictedquarts = np.empty(shape = (0,4))\n",
    "    savecounter = 0 # this will be reset\n",
    "    \n",
    "    # set your current combination of four taxa\n",
    "    fourtaxa= alltipcombns[np.random.choice(range(targetlen))]\n",
    "\n",
    "    # get one snp at each locus -- might eventually be better to build a distribution at each locus, or \n",
    "    # at least compare quality of inference done both ways\n",
    "\n",
    "    # before, I'd been getting all informative, complete SNPs at each locus and then randomly selecting. \n",
    "    # Much more efficient this way, shuffling each locus randomly and then selecting first informative SNP\n",
    "\n",
    "    reducedgene = np.empty(shape = (0,4))\n",
    "    for geneidx in range(len(genes_alltaxa)):\n",
    "        currentgene = genes_alltaxa[geneidx]\n",
    "        orderedsamples = range(len(currentgene))\n",
    "        np.random.shuffle(orderedsamples)\n",
    "        trigger = 0\n",
    "        q = 0\n",
    "        while (trigger == 0) and (q < (len(currentgene)-1)):\n",
    "            currentgene = [genes_alltaxa[geneidx][orderedsamples[q]][taxon] for taxon in fourtaxa]\n",
    "            q += 1\n",
    "            if ((len(set(currentgene).union(set(['A','G','C','T']))) == 4) and (len(set(currentgene)) > 1)):\n",
    "                reducedgene = np.vstack([reducedgene,currentgene])\n",
    "                trigger = 1\n",
    "\n",
    "    arr0123 = np.array(reducedgene)\n",
    "    possible_configs = [[0,1,2,3],[0,2,1,3],[0,3,1,2]]\n",
    "    arr0123 = np.where(arr0123=='A',0,arr0123)\n",
    "    arr0123 = np.where(arr0123=='C',1,arr0123)\n",
    "    arr0123 = np.where(arr0123=='G',2,arr0123)\n",
    "    arr0123 = np.where(arr0123=='T',3,arr0123)\n",
    "    arr0123 = arr0123.astype(int)\n",
    "\n",
    "    # make index matrix for each pair of bases. This assigns row / col number for full 16x16 matrix\n",
    "    indexmat = np.array(range(16))\n",
    "    indexmat.shape=(4,4)\n",
    "\n",
    "            # make 16x16 matrix of zeroes\n",
    "            # order across matrix is 00,01,02,03,10,11,12,13,20,21,22,23,30,31,32,33\n",
    "            # not good use of space\n",
    "    three_possible = []\n",
    "    for q in possible_configs:\n",
    "        temp_rearrangement = arr0123[:,q]\n",
    "        fullmat0123 = np.zeros(shape=(16,16))\n",
    "        for i in range(len(temp_rearrangement)):\n",
    "                    # get row number \n",
    "            rownum = int(indexmat[temp_rearrangement[i][0:2][0],temp_rearrangement[i][0:2][1]])\n",
    "                    # get col number\n",
    "            colnum = int(indexmat[temp_rearrangement[i][2:4][0],temp_rearrangement[i][2:4][1]])\n",
    "            fullmat0123[rownum,colnum] = fullmat0123[rownum,colnum] + 1\n",
    "        three_possible.append((fullmat0123.flatten()/max(fullmat0123.flatten())))\n",
    "    print \"Four taxa: \" + str(fourtaxa)\n",
    "    toyplot.matrix(three_possible[0].reshape(16,16))\n",
    "    toyplot.matrix(three_possible[1].reshape(16,16))\n",
    "    toyplot.matrix(three_possible[2].reshape(16,16))\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_mammal_quarts(totalseqs_path,\n",
    "                     snpmap_path,\n",
    "                     output_path,\n",
    "                     writing_interval = 200,\n",
    "                     starting_combo = 0\n",
    "                    ):\n",
    "    totalseqs = np.genfromtxt(totalseqs_path,dtype='str')\n",
    "    snpmap = np.loadtxt(snpmap_path).astype(int)\n",
    "\n",
    "    alltipcombns=np.array(list(itertools.combinations(range(len(totalseqs[0])), 4)))\n",
    "    alltipcombns = alltipcombns.astype(int)\n",
    "\n",
    "    genes_alltaxa = [totalseqs[snpmap[0][i]:snpmap[1][i]] for i in range(len(snpmap[0]))]\n",
    "\n",
    "    if not starting_combo:\n",
    "        combocounter = 0\n",
    "        orig_file = np.empty(shape = (0,4))\n",
    "        np.savetxt(output_path,orig_file)\n",
    "    else:\n",
    "        combocounter = starting_combo\n",
    "    targetlen = len(alltipcombns)\n",
    "\n",
    "    # the first time you run this, run the next two lines to make a new file:\n",
    "\n",
    "    #orig_file = np.empty(shape = (0,4))\n",
    "    #np.savetxt(\"download_simseqs/mammal_quarts.txt\",orig_file)\n",
    "\n",
    "\n",
    "    allpredictedquarts = np.empty(shape = (0,4))\n",
    "    savecounter = 0 # this will be reset\n",
    "    \n",
    "    # set your current combination of four taxa\n",
    "    fourtaxa= alltipcombns[np.random.choice(range(targetlen))]\n",
    "\n",
    "    # get one snp at each locus -- might eventually be better to build a distribution at each locus, or \n",
    "    # at least compare quality of inference done both ways\n",
    "\n",
    "    # before, I'd been getting all informative, complete SNPs at each locus and then randomly selecting. \n",
    "    # Much more efficient this way, shuffling each locus randomly and then selecting first informative SNP\n",
    "\n",
    "    reducedgene = np.empty(shape = (0,4))\n",
    "    for geneidx in range(len(genes_alltaxa)):\n",
    "        currentgene = genes_alltaxa[geneidx]\n",
    "        orderedsamples = range(len(currentgene))\n",
    "        np.random.shuffle(orderedsamples)\n",
    "        trigger = 0\n",
    "        q = 0\n",
    "        while (trigger == 0) and (q < (len(currentgene)-1)):\n",
    "            currentgene = [genes_alltaxa[geneidx][orderedsamples[q]][taxon] for taxon in fourtaxa]\n",
    "            q += 1\n",
    "            if ((len(set(currentgene).union(set(['A','G','C','T']))) == 4) and (len(set(currentgene)) > 1)):\n",
    "                reducedgene = np.vstack([reducedgene,currentgene])\n",
    "                trigger = 1\n",
    "\n",
    "    arr0123 = np.array(reducedgene)\n",
    "    possible_configs = [[0,1,2,3],[0,2,1,3],[0,3,1,2]]\n",
    "    arr0123 = np.where(arr0123=='A',0,arr0123)\n",
    "    arr0123 = np.where(arr0123=='C',1,arr0123)\n",
    "    arr0123 = np.where(arr0123=='G',2,arr0123)\n",
    "    arr0123 = np.where(arr0123=='T',3,arr0123)\n",
    "    arr0123 = arr0123.astype(int)\n",
    "\n",
    "    # make index matrix for each pair of bases. This assigns row / col number for full 16x16 matrix\n",
    "    indexmat = np.array(range(16))\n",
    "    indexmat.shape=(4,4)\n",
    "\n",
    "            # make 16x16 matrix of zeroes\n",
    "            # order across matrix is 00,01,02,03,10,11,12,13,20,21,22,23,30,31,32,33\n",
    "            # not good use of space\n",
    "    three_possible = []\n",
    "    for q in possible_configs:\n",
    "        temp_rearrangement = arr0123[:,q]\n",
    "        fullmat0123 = np.zeros(shape=(16,16))\n",
    "        for i in range(len(temp_rearrangement)):\n",
    "                    # get row number \n",
    "            rownum = int(indexmat[temp_rearrangement[i][0:2][0],temp_rearrangement[i][0:2][1]])\n",
    "                    # get col number\n",
    "            colnum = int(indexmat[temp_rearrangement[i][2:4][0],temp_rearrangement[i][2:4][1]])\n",
    "            fullmat0123[rownum,colnum] = fullmat0123[rownum,colnum] + 1\n",
    "        three_possible.append((fullmat0123.flatten()/max(fullmat0123.flatten())))\n",
    "    print \"Four taxa: \" + str(fourtaxa)\n",
    "    toyplot.matrix(three_possible[0].reshape(16,16))\n",
    "    toyplot.matrix(three_possible[1].reshape(16,16))\n",
    "    toyplot.matrix(three_possible[2].reshape(16,16))\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalseqs = np.genfromtxt(\"download_simseqs/concat_mammal_genes.gz\",dtype='str')\n",
    "snpmap = np.loadtxt(\"download_simseqs/concat_mammal_map.gz\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_patterns(goodbases):\n",
    "    patterns = np.empty(shape = (0,4))\n",
    "    for base in range(len(goodbases)):\n",
    "        d = {ni: indi for indi, ni in enumerate(set(goodbases[base]))}\n",
    "        patterns = np.vstack([patterns,(np.vectorize(d.__getitem__)(goodbases[base]))])\n",
    "    return(patterns.astype(int))\n",
    "@jit\n",
    "def most_freq_pattern(the_patterns):\n",
    "    unique_patterns, freqs  = np.unique(the_patterns,axis = 0,return_counts=True)\n",
    "    return unique_patterns[np.argmax(freqs)]\n",
    "@jit\n",
    "def f(genes_alltaxa,geneidx,fourtaxa):\n",
    "        currentgene = [[genes_alltaxa[geneidx][base][taxon] for taxon in fourtaxa] for base in range(len(genes_alltaxa[geneidx]))]\n",
    "        return np.array(currentgene)\n",
    "@jit\n",
    "def exclude(fullgene):\n",
    "    return np.array([sum(fullgene[q])<= 12 and len(set(fullgene[q])) > 1 for q in xrange(len(fullgene))])\n",
    "\n",
    "totalseqs = totalseqs.view(np.uint8)\n",
    "totalseqs = np.where(totalseqs==65,0,totalseqs)\n",
    "totalseqs = np.where(totalseqs==67,1,totalseqs)\n",
    "totalseqs = np.where(totalseqs==71,2,totalseqs)\n",
    "totalseqs = np.where(totalseqs==84,3,totalseqs)\n",
    "genes_alltaxa = [totalseqs[snpmap[0][i]:snpmap[1][i]] for i in range(len(snpmap[0]))]\n",
    "alltipcombns=np.array(list(itertools.combinations(range(len(totalseqs[0])), 4)))\n",
    "alltipcombns = alltipcombns.astype(int)\n",
    "\n",
    "combocounter = 0\n",
    "orig_file = np.empty(shape = (0,4))\n",
    "#    np.savetxt(output_path,orig_file)\n",
    "\n",
    "targetlen = len(alltipcombns)\n",
    "\n",
    "\n",
    "\n",
    "allpredictedquarts = np.empty(shape = (0,4))\n",
    "savecounter = 0 # this will be reset\n",
    "\n",
    "# set your current combination of four taxa\n",
    "fourtaxa= alltipcombns[np.random.choice(range(targetlen))]\n",
    "\n",
    "# get one snp at each locus -- might eventually be better to build a distribution at each locus, or \n",
    "# at least compare quality of inference done both ways\n",
    "\n",
    "# before, I'd been getting all informative, complete SNPs at each locus and then randomly selecting. \n",
    "# Much more efficient this way, shuffling each locus randomly and then selecting first informative SNP\n",
    "\n",
    "reducedgene = np.empty(shape = (0,4))\n",
    "for geneidx in range(len(genes_alltaxa)):\n",
    "    fullgene = f(genes_alltaxa,geneidx,fourtaxa)\n",
    "    goodbases = fullgene[exclude(fullgene)]\n",
    "    if len(goodbases) > 0:\n",
    "        the_patterns = get_patterns(goodbases)\n",
    "        indices = np.where((the_patterns == most_freq_pattern(the_patterns)).all(axis=1))[0]\n",
    "        reducedgene = np.vstack([reducedgene,goodbases[int(np.random.choice(indices,1))]])\n",
    "        reducedgene = np.vstack([reducedgene,goodbases[np.random.choice(range(len(goodbases)),10)]])\n",
    "    print(geneidx)\n",
    "# make index matrix for each pair of bases. This assigns row / col number for full 16x16 matrix\n",
    "indexmat = np.array(range(16))\n",
    "indexmat.shape=(4,4)\n",
    "\n",
    "        # make 16x16 matrix of zeroes\n",
    "        # order across matrix is 00,01,02,03,10,11,12,13,20,21,22,23,30,31,32,33\n",
    "        # not good use of space\n",
    "three_possible = []\n",
    "possible_configs = [[0,1,2,3],[0,2,1,3],[0,3,1,2]]\n",
    "arr0123 = copy.deepcopy(reducedgene)\n",
    "arr0123 = arr0123.astype(int)\n",
    "for q in possible_configs:\n",
    "    temp_rearrangement = arr0123[:,q]\n",
    "    fullmat0123 = np.zeros(shape=(16,16))\n",
    "    for i in range(len(temp_rearrangement)):\n",
    "                # get row number \n",
    "        rownum = int(indexmat[temp_rearrangement[i][0:2][0],temp_rearrangement[i][0:2][1]])\n",
    "                # get col number\n",
    "        colnum = int(indexmat[temp_rearrangement[i][2:4][0],temp_rearrangement[i][2:4][1]])\n",
    "        fullmat0123[rownum,colnum] = fullmat0123[rownum,colnum] + 1\n",
    "    three_possible.append((fullmat0123.flatten()/max(fullmat0123.flatten())))\n",
    "print \"Four taxa: \" + str(fourtaxa)\n",
    "toyplot.matrix(three_possible[0].reshape(16,16))\n",
    "toyplot.matrix(three_possible[1].reshape(16,16))\n",
    "toyplot.matrix(three_possible[2].reshape(16,16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "            tf.reset_default_graph()\n",
    "            x = tf.placeholder(tf.float32, [None, 256])\n",
    "            W = tf.Variable(tf.zeros([256, 2]))\n",
    "            b = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "            y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "            y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "            # Add ops to save and restore all the variables.\n",
    "            saver = tf.train.Saver()\n",
    "            # Later, launch the model, use the saver to restore variables from disk, and\n",
    "            # do some work with the model.\n",
    "            with tf.Session() as sess:\n",
    "                # Restore variables from disk.\n",
    "#                with nostdout():\n",
    "                saver.restore(sess, \"download_simseqs/saved_mo.ckpt\")\n",
    "                #print(\"Model restored.\")\n",
    "                predictions = sess.run(y, feed_dict={x: three_possible[0:3]})\n",
    "#                prediction = predictions[0];"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
